library(tree)
library(rpart)
library(caret)
library(rattle)
library(modelr)
library(rpart.plot)
library(klaR)
library(RColorBrewer)
library(e1071)
source("r/functions.R")
dataset<-read_csv("data/diabetes.txt",col_names=c("timespreg","plaglu",
"diastolic","triceps",
"serum","bmi","diabped",
"age","diabetes"))
dataset$diabetes<-factor(dataset$diabetes,levels=c(0,1)
,labels = c("No","Yes"))
finaldataset<-dataset[dataset$plaglu!=0,]
finaldataset<-finaldataset[finaldataset$bmi!=0,]
finaldataset<-finaldataset[,c(-4,-5)]
finaldataset<-finaldataset[finaldataset$bmi!=max(finaldataset$bmi),]
finaldataset$diabped<-log(finaldataset$diabped)
finaldataset$bmi<-log(finaldataset$bmi)
table(finaldataset$diabetes)
diastolic<-dataset[dataset$diastolic!=0,]
mu<-mean(diastolic$diastolic)
finaldataset<-mutate(finaldataset,diastolic=ifelse(diastolic==0,mu,diastolic))
rm(diastolic)
normalize<-as.data.frame(scale(finaldataset[,-7]))
normalize$diabetes<-finaldataset$diabetes
set.seed(1234)
trainidx<-createDataPartition(y = finaldataset$diabetes,
list = FALSE,p = 0.7)
train<-finaldataset[trainidx,]
notrain<-finaldataset[-trainidx,]
set.seed(1234)
testidx<-createDataPartition(y=notrain$diabetes,list=FALSE,p=0.5)
test<-notrain[testidx,]
validate<-notrain[-testidx,]
normtrain<-normalize[trainidx,]
normnotrain<-normalize[-trainidx,]
normtest<-normnotrain[testidx,]
normvalidate<-normnotrain[-testidx,]
set.seed(1234)
dtree<-rpart(diabetes~.,data=train,method="class")
dtree.pred<-predict(dtree,validate,type = "class")
dtree.out<-confusionMatrix(data=dtree.pred,reference = validate$diabetes,positive="Yes")
printcp(dtree)
dtree.prune<-prune(dtree,cp = 0.028)
dtree.prune.pred<-predict(dtree.prune,validate,type="class")
dtree.prune.out<-confusionMatrix(data=dtree.prune.pred,reference = validate$diabetes,positive="Yes")
knn.pred<-list()
knn.missrate<-c()
for (i in 1:25){
a<-knn(train = normtrain[,-7],test=normvalidate[,-7],k = i,cl=normtrain$diabetes)
knn.pred[[i]]<-a
knn.missrate[i]<-mean(ifelse(knn.pred[[i]]==normvalidate$diabetes,FALSE,TRUE))
}
names(knn.pred)<-paste("K=",c(1:25),sep="")
knn.plot<-ggplot()+geom_line(aes(x=k,y=knn.missrate))
knn.plot
k<-which.min(knn.missrate)
knn.plot<-ggplot()+geom_line(aes(x=c(1:25),y=knn.missrate))
knn.plot
k<-which.min(knn.missrate)
knn.out<-confusionMatrix(data=knn.pred[[k]],reference=normvalidate$diabetes,positive="Yes")
knn.out
naivetrain<-train[,-7]
naivelabels<-train$diabetes
naive<-train(naivetrain,naivelabels,"nb",trControl=trainControl(method="cv",number=10))
naive.pred<-predict(naive,newdata = validate)
naive.out<-confusionMatrix(data=naive.pred,reference=validate$diabetes,positive="Yes")
naive.out
confmodels<-list(dtree.prune.out,
knn.out,naive.out)
modelnames<-c("Decision Tree Prune","KNN",
"Naive Bayes")
comp<-comparisondf(confmodels,modelnames)
View(comp)
knn.plot<-ggplot()+geom_line(aes(x=k,y=knn.missrate))
knn.plot
k<-c(1:25)
knn.plot<-ggplot()+geom_line(aes(x=k,y=knn.missrate))
knn.plot
k<-which.min(knn.missrate)
k
tree.pred<-as.data.frame(predict(dtree.prune,validate,type="prob"))
tree.pred$actual<-ifelse(validate$diabetes=="Yes",1,0)
tree.pred$class<-as.data.frame(predict(dtree.prune,validate,type="class"))
tree.pred$prob<-ifelse(tree.pred$class=="Yes",tree.pred$Yes,tree.pred$No)
logloss(tree.pred$prob,tree.pred$actual)
naive.pred<-as.data.frame(predict(naive,validate,type="prob"))
naive.pred$actual<-ifelse(validate$diabetes=="Yes",1,0)
naive.pred$class<-as.data.frame(predict(naive,validate,type="raw"))
naive.pred$prob<-ifelse(naive.pred$class=="Yes",naive.pred$Yes,naive.pred$No)
logloss(naive.pred$prob,naive.pred$actual)
knn.prob<-list()
for (i in 1:25){
a<-knn(train = normtrain[,-7],test=normvalidate[,-7],k = i,cl=normtrain$diabetes,prob = TRUE)
knn.prob[[i]]<-a
}
names(knn.prob)<-paste("K=",c(1:25),sep="")
knn.log<-as.data.frame(knn.prob[[k]])
knn.log$actual<-ifelse(validate$diabetes=="Yes",1,0)
knn.log$class<-knn.prob[[k]]
knn.log$prob<-attr(knn.prob[[k]],"prob")
logloss(knn.log$prob,knn.log$actual)
knn.pred<-list()
knn.missrate<-c()
knn.pred<-list()
knn.missrate<-c()
for (i in 1:50){
a<-knn(train = normtrain[,-7],test=normvalidate[,-7],k = i,cl=normtrain$diabetes)
knn.pred[[i]]<-a
knn.missrate[i]<-mean(ifelse(knn.pred[[i]]==normvalidate$diabetes,FALSE,TRUE))
}
k<-c(1:50)
names(knn.pred)<-paste("K=",k,sep="")
k<-which.min(knn.missrate)
k
knn.plot
knn.plot<-ggplot()+geom_line(aes(x=k,y=knn.missrate))
k<-c(1:50)
knn.plot<-ggplot()+geom_line(aes(x=k,y=knn.missrate))
knn.plot
library(tidyverse)
library(MASS)
library(rpart)
library(class)
library(modelr)
library(caret)
library(tree)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(klaR)
library(e1071)
source("r/functions.R")
dataset<-read_csv("data/diabetes.txt",col_names=c("timespreg","plaglu",
"diastolic","triceps",
"serum","bmi","diabped",
"age","diabetes"))
dataset$diabetes<-factor(dataset$diabetes,levels=c(0,1)
,labels = c("No","Yes"))
finaldataset<-dataset[dataset$plaglu!=0,]
finaldataset<-finaldataset[finaldataset$bmi!=0,]
finaldataset<-finaldataset[,c(-4,-5)]
finaldataset<-finaldataset[finaldataset$bmi!=max(finaldataset$bmi),]
finaldataset$diabped<-log(finaldataset$diabped)
finaldataset$bmi<-log(finaldataset$bmi)
diastolic<-dataset[dataset$diastolic!=0,]
mu<-mean(diastolic$diastolic)
finaldataset<-mutate(finaldataset,diastolic=ifelse(diastolic==0,mu,diastolic))
rm(diastolic)
normalize<-as.data.frame(scale(finaldataset[,-7]))
normalize$diabetes<-finaldataset$diabetes
set.seed(1234)
trainidx<-createDataPartition(y = finaldataset$diabetes,
list = FALSE,p = 0.7)
train<-finaldataset[trainidx,]
notrain<-finaldataset[-trainidx,]
set.seed(1234)
testidx<-createDataPartition(y=notrain$diabetes,list=FALSE,p=0.5)
test<-notrain[testidx,]
validate<-notrain[-testidx,]
normtrain<-normalize[trainidx,]
normnotrain<-normalize[-trainidx,]
normtest<-normnotrain[testidx,]
normvalidate<-normnotrain[-testidx,]
set.seed(1234)
dtree<-rpart(diabetes~.,data=train,method="class")
dtree.pred<-predict(dtree,validate,type = "class")
dtree.out<-confusionMatrix(data=dtree.pred,reference = validate$diabetes,positive="Yes")
printcp(dtree)
dtree.prune<-prune(dtree,cp = 0.028)
dtree.prune.pred<-predict(dtree.prune,validate,type="class")
dtree.prune.out<-confusionMatrix(data=dtree.prune.pred,reference = validate$diabetes,positive="Yes")
dtree.prune.out
knn.pred<-list()
knn.missrate<-c()
for (i in 1:25){
a<-knn(train = normtrain[,-7],test=normvalidate[,-7],k = i,cl=normtrain$diabetes)
knn.pred[[i]]<-a
knn.missrate[i]<-mean(ifelse(knn.pred[[i]]==normvalidate$diabetes,FALSE,TRUE))
}
k<-c(1:25)
names(knn.pred)<-paste("K=",c(1:25),sep="")
knn.plot<-ggplot()+geom_line(aes(x=k,y=knn.missrate))
knn.plot
ggsave("plots/knnplot.jpg",knn.plot,width=8,height=4)
k<-which.min(knn.missrate)
knn.out<-confusionMatrix(data=knn.pred[[k]],reference=normvalidate$diabetes,positive="Yes")
knn.out
k
naivetrain<-train[,-7]
naivelabels<-train$diabetes
naive<-train(naivetrain,naivelabels,"nb",trControl=trainControl(method="cv",number=10))
naive.pred<-predict(naive,newdata = validate)
naive.out<-confusionMatrix(data=naive.pred,reference=validate$diabetes,positive="Yes")
naive.out
confmodels<-list(dtree.prune.out,
knn.out,naive.out)
modelnames<-c("Decision Tree Prune","KNN",
"Naive Bayes")
comp<-comparisondf(confmodels,modelnames)
ggsave("plots/accuracy.jpg",complot,width=8,height=4)
complot<-ggplot(data=comp,aes(x=Model,y=Accuracy))+geom_col(fill="green4")
ggsave("plots/accuracy.jpg",complot,width=8,height=4)
tree.pred<-as.data.frame(predict(dtree.prune,validate,type="prob"))
tree.pred$actual<-ifelse(validate$diabetes=="Yes",1,0)
tree.pred$class<-as.data.frame(predict(dtree.prune,validate,type="class"))
tree.pred$prob<-ifelse(tree.pred$class=="Yes",tree.pred$Yes,tree.pred$No)
logloss(tree.pred$prob,tree.pred$actual)
naive.pred<-as.data.frame(predict(naive,validate,type="prob"))
naive.pred$actual<-ifelse(validate$diabetes=="Yes",1,0)
naive.pred$class<-as.data.frame(predict(naive,validate,type="raw"))
naive.pred$prob<-ifelse(naive.pred$class=="Yes",naive.pred$Yes,naive.pred$No)
logloss(naive.pred$prob,naive.pred$actual)
knn.prob<-list()
for (i in 1:25){
a<-knn(train = normtrain[,-7],test=normvalidate[,-7],k = i,cl=normtrain$diabetes,prob = TRUE)
knn.prob[[i]]<-a
}
names(knn.prob)<-paste("K=",c(1:25),sep="")
knn.log<-as.data.frame(knn.prob[[k]])
knn.log$actual<-ifelse(validate$diabetes=="Yes",1,0)
knn.log$class<-knn.prob[[k]]
knn.log$prob<-attr(knn.prob[[k]],"prob")
logloss(knn.log$prob,knn.log$actual)
knn.pred
library(tidyverse)
library(MASS)
library(rpart)
library(class)
library(modelr)
library(tree)
library(caret)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(klaR)
library(e1071)
source("r/functions.R")
source('C:/Users/Administrador.000/Desktop/Sebastian/Repos/diabetes/script - copia.R', echo=TRUE)
comp
View(comp)
fitcontrol<-trainControl(method = "repeatedcv",number = 20,repeats=3,classProbs = TRUE,savePredictions = TRUE,returnResamp = "all")
grid<-expand.grid(k=c(1:25))
knn.caret<-train(diabetes~.,data=train,method="knn",preProcess=c("center","scale"),
trControl=fitcontrol,tuneGrid=grid)
knn.caret
fitcontrol<-trainControl(method = "repeatedcv",number = 20,repeats=3,classProbs = TRUE,savePredictions = TRUE,returnResamp = "all")
grid<-expand.grid(k=c(1:50))
knn.caret<-train(diabetes~.,data=train,method="knn",preProcess=c("center","scale"),
trControl=fitcontrol,tuneGrid=grid)
knn.caret
knn.caret.pred<-predict(knn.caret,newdata=notrain)
confusionMatrix(knn.caret.pred,reference=notrain$diabetes,positive="Yes")
confusionMatrix(knn.caret.pred,reference=validate$diabetes,positive="Yes")
knn.caret.pred<-predict(knn.caret,newdata=validate)
confusionMatrix(knn.caret.pred,reference=validate$diabetes,positive="Yes")
fitcontrol<-trainControl(method = "repeatedcv",number = 10,repeats=3,classProbs = TRUE,savePredictions = TRUE,returnResamp = "all")
grid<-expand.grid(k=c(11))
knn.caret<-train(diabetes~.,data=train,method="knn",preProcess=c("center","scale"),
trControl=fitcontrol,tuneGrid=grid)
knn.caret
knn.caret.pred<-predict(knn.caret,newdata=validate)
confusionMatrix(knn.caret.pred,reference=validate$diabetes,positive="Yes")
postResample(knn.caret.pred,notrain$diabetes)
knn.caret.pred
knn.caret.pred<-predict(knn.caret,newdata=validate,type="prob")
knn.caret.pred
ggplot(knn.caret)
knngrid<-expand.grid(k=c(1:50))
knn.caret<-train(diabetes~.,data=train,method="knn",preProcess=c("center","scale"),
trControl=fitcontrol,tuneGrid=knngrid)
confusionMatrix(knn.caret.pred,reference=validate$diabetes,positive="Yes")
knn.caret.pred<-predict(knn.caret,newdata=validate,type="raw")
knn.caret.pred
confusionMatrix(knn.caret.pred,reference=validate$diabetes,positive="Yes")
ggplot(knn.caret)
knn.caret
rpart.caret<-train(diabetes~.,data=train,method="rpart",trControl=fitcontrol)
rpart.caret
rpart.caret.pred<-predict(rpart.caret,newdata=notrain,type="raw")
confusionMatrix(rpart.caret.pred,reference=notrain$diabetes,positive="Yes")
ggplot(rpart.caret)
rpart.caret<-train(diabetes~.,data=train,method="rpart",trControl=fitcontrol,tuneLength=30)
rpart.caret
ggplot(rpart.caret)
fancyRpartPlot(rpart.caret$finalModel)
jpeg("plots/dtreeprune.jpg")
fancyRpartPlot(dtree.prune)
dev.off()
getwd()
jpeg("plots/dtreeprune.jpg")
fancyRpartPlot(dtree.prune)
dev.off()
naive.caret<-train(diabetes~.,data=train,method="nb",trControl=fitcontrol,tuneLength=30)
naive.caret
naive.caret.pred<-predict(naive.caret,newdata=notrain)
warnings()
naive.caret.pred
naive.caret.pred<-predict(naive.caret,newdata=notrain,type="prob")
naive.caret.pred
1-e15
1^-15
1^(-15)
1^(10)
1^(-10)
5^(-10)
naive.caret.out<-confusionMatrix(rpart.caret.pred,reference=notrain$diabetes,positive="Yes")
rpart.caret.out<-confusionMatrix(rpart.caret.pred,reference=notrain$diabetes,positive="Yes")
knn.caret.out<-confusionMatrix(knn.caret.pred,reference=validate$diabetes,positive="Yes")
naive.caret.out<-confusionMatrix(rpart.caret.pred,reference=notrain$diabetes,positive="Yes")
rpart.caret.out<-confusionMatrix(rpart.caret.pred,reference=notrain$diabetes,positive="Yes")
knn.caret.out<-confusionMatrix(knn.caret.pred,reference=validate$diabetes,positive="Yes")
complist<-c(knn.caret.out,rpart.caret.out,naive.caret.out)
carmod<-c("KNN","Decision Tree","Naive Bayes")
comparisondf(complist,carmod)
comp<-comparisondf(confmodels,modelnames)
comparsiondf(knn.caret.out,"KNN")
comparisondf(knn.caret.out,"KNN")
complist<-list(knn.caret.out,rpart.caret.out,naive.caret.out)
carmod<-list("KNN","Decision Tree","Naive Bayes")
comparisondf(complist,carmod)
aaa<-comparisondf(knn.caret.out,"KNN")
aaa<-comparisondf(complist,carmod)
aaa
View(aaa)
complist<-list(knn.caret.out,rpart.caret.out,naive.caret.out)
carmod<-c("KNN","Decision Tree","Naive Bayes")
caretcomp<-comparisondf(complist,carmod)
knn.caret.out<-confusionMatrix(knn.caret.pred,reference=notrain$diabetes,positive="Yes")
knn.caret.pred<-predict(knn.caret,newdata=notrain,type="raw")
knn.caret.out<-confusionMatrix(knn.caret.pred,reference=notrain$diabetes,positive="Yes")
complist<-list(knn.caret.out,rpart.caret.out,naive.caret.out)
carmod<-c("KNN","Decision Tree","Naive Bayes")
caretcomp<-comparisondf(complist,carmod)
caretcomp
knn.pred<-list()
knn.missrate<-c()
for (i in 1:25){
a<-knn(train = normtrain,test=normvalidate,k = i,cl=normtrain$diabetes)
knn.pred[[i]]<-a
knn.missrate[i]<-mean(ifelse(knn.pred[[i]]==normvalidate$diabetes,FALSE,TRUE))
}
a<-knn(train = normtrain[,-7],test=normvalidate[-7],k = i,cl=normtrain$diabetes)
knn.pred[[i]]<-a
knn.missrate[i]<-mean(ifelse(knn.pred[[i]]==normvalidate$diabetes,FALSE,TRUE))
knn.pred<-list()
knn.missrate<-c()
for (i in 1:25){
a<-knn3(train = normtrain[,-7],test=normvalidate[-7],k = i,cl=normtrain$diabetes)
knn3()d[[i]]<-a
knn.missrate[i]<-mean(ifelse(knn.pred[[i]]==normvalidate$diabetes,FALSE,TRUE))
}
k<-c(1:25)
names(knn.pred)<-paste("K=",k,sep="")
koptimal<-which.min(knn.missrate)
koptimal<-which.min(knn.missrate)
knn.pred<-list()
knn.missrate<-c()
for (i in 1:25){
a<-knn3(train = normtrain[,-7],test=normvalidate[-7],k = i,cl=normtrain$diabetes)
knn.pred[[i]]<-a
knn.missrate[i]<-mean(ifelse(knn.pred[[i]]==normvalidate$diabetes,FALSE,TRUE))
}
k<-c(1:25)
names(knn.pred)<-paste("K=",k,sep="")
koptimal<-which.min(knn.missrate)
knn.pred<-list()
knn.missrate<-c()
for (i in 1:25){
a<-knn3(train = normtrain[,-7],test=normvalidate[-7],k = i,cl=normtrain$diabetes)
knn.pred[[i]]<-a
knn.missrate[i]<-mean(ifelse(knn.pred[[i]]==normvalidate$diabetes,FALSE,TRUE))
}
knn.pred<-list()
knn.missrate<-c()
for (i in 1:25){
a<-knn(train = normtrain[,-7],test=normvalidate[-7],k = i,cl=normtrain$diabetes)
knn.pred[[i]]<-a
knn.missrate[i]<-mean(ifelse(knn.pred[[i]]==normvalidate$diabetes,FALSE,TRUE))
}
k<-c(1:25)
names(knn.pred)<-paste("K=",k,sep="")
koptimal<-which.min(knn.missrate)
koptimal
knn.out<-confusionMatrix(data=knn.pred[[koptimal]],reference=normvalidate$diabetes,positive="Yes")
knn.out
knn.pred<-list()
knn.missrate<-c()
for (i in 1:25){
a<-knn(train = normtrain[,-7],test=normvalidate[-7],k = i,cl=normtrain$diabetes)
knn.pred[[i]]<-a
knn.missrate[i]<-mean(ifelse(knn.pred[[i]]==normvalidate$diabetes,FALSE,TRUE))
}
koptimal<-which.min(knn.missrate)
koptimal
knn.pred<-list()
knn.missrate<-c()
for (i in 1:25){
a<-knn(train = normtrain[,-7],test=normvalidate[-7],k = i,cl=normtrain$diabetes)
knn.pred[[i]]<-a
knn.missrate[i]<-mean(ifelse(knn.pred[[i]]==normvalidate$diabetes,FALSE,TRUE))
}
koptimal<-which.min(knn.missrate)
koptimal
knn.out<-confusionMatrix(data=knn.pred[[koptimal]],reference=normvalidate$diabetes,positive="Yes")
knn.out
knn.pred<-list()
knn.missrate<-c()
for (i in 1:25){
a<-knn(train = normtrain[,-7],test=normvalidate[-7],k = i,cl=normtrain$diabetes)
knn.pred[[i]]<-a
knn.missrate[i]<-mean(ifelse(knn.pred[[i]]==normvalidate$diabetes,FALSE,TRUE))
}
k<-c(1:25)
names(knn.pred)<-paste("K=",k,sep="")
knn.pred<-list()
knn.missrate<-c()
for (i in 1:25){
a<-knn(train = normtrain[,-7],test=normvalidate[-7],k = i,cl=normtrain$diabetes)
knn.pred[[i]]<-a
knn.missrate[i]<-mean(ifelse(knn.pred[[i]]==normvalidate$diabetes,FALSE,TRUE))
}
koptimal<-which.min(knn.missrate)
koptimal
1-e15
1e-15
naive.pred$newprob<-min(max(naive.pred$prob,1e-15),1-1e-15)
naive.pred
naive.pred$newprob<-pmin(pmax(naive.pred$prob,1e-15),1-1e-15)
naive.pred
logloss(naive.pred$newprob,naive.pred$actual)
naive.pred$log<-naive.pred$actual*log(naive.pred$newprob)+(1-naive.pred$actual)*log(1-naive.pred$newprob)
View(naive.pred)
knn.log
logloss(naive.pred$newprob,naive.pred$actual)
logloss(naive.pred$prob,naive.pred$actual)
source('C:/Users/Administrador.000/Desktop/Sebastian/Repos/diabetes/script.R', echo=TRUE)
comp
koptimal
knn.pred<-list()
knn.missrate<-c()
for (i in 1:25){
set.seed(1234)
a<-knn(train = normtrain[,-7],test=normvalidate[-7],k = i,cl=normtrain$diabetes)
knn.pred[[i]]<-a
knn.missrate[i]<-mean(ifelse(knn.pred[[i]]==normvalidate$diabetes,FALSE,TRUE))
}
k<-c(1:25)
names(knn.pred)<-paste("K=",k,sep="")
knn.plot<-ggplot()+geom_line(aes(x=k,y=knn.missrate))
knn.plot
ggsave("plots/knnplot.jpg",knn.plot,width=8,height=4)
koptimal<-which.min(knn.missrate)
koptimal
complist<-list(knn.caret.out,knn.out,rpart.caret.out,dtree.prune.out,
naive.caret.out,naive.out)
carmod<-c("Caret KNN","KNN","Caret Decision Tree","Decision Tree",
"Caret Naive Bayes","Naive Bayes")
totalcomp<-comparisondf(complist,carmod)
View(totalcomp)
knn.caret.pred<-predict(knn.caret,newdata=validate,type="raw")
knn.caret.out<-confusionMatrix(knn.caret.pred,reference=validate$diabetes,positive="Yes")
rpart.caret.pred<-predict(rpart.caret,newdata=validate,type="prob")
rpart.caret.out<-confusionMatrix(rpart.caret.pred,reference=validate$diabetes,positive="Yes")
rpart.caret.pred<-predict(rpart.caret,newdata=validate)
rpart.caret.out<-confusionMatrix(rpart.caret.pred,reference=validate$diabetes,positive="Yes")
naive.caret.pred<-predict(naive.caret,newdata=validate,type="prob")
naive.caret.out<-confusionMatrix(rpart.caret.pred,reference=validate$diabetes,positive="Yes")
naive.caret.pred<-predict(naive.caret,newdata=validate)
naive.caret.out<-confusionMatrix(rpart.caret.pred,reference=validate$diabetes,positive="Yes")
complist<-list(knn.caret.out,knn.out,rpart.caret.out,dtree.prune.out,
naive.caret.out,naive.out)
carmod<-c("Caret KNN","KNN","Caret Decision Tree","Decision Tree",
"Caret Naive Bayes","Naive Bayes")
totalcomp<-comparisondf(complist,carmod)
View(totalcomp)
View(totalcomp)
library(class)
source('C:/Users/Administrador.000/Desktop/Sebastian/Repos/diabetes/script.R', echo=TRUE)
printcp(dtree)
rpart.caret
fancyRpartPlot(rpart.caret$finalModel)
totalcomp
logloss(naive.pred$prob,naive.pred$actual)
logloss(knn.log$prob,knn.log$actual)
logloss(tree.pred$prob,tree.pred$actual)
naive.caret
rf.caret <- train(diabetes~., data=train, method="rf", trControl=traincontrol)
rf.caret <- train(diabetes~., data=train, method="rf", trControl=fitcontrol)
rf.caret
rf.caret.pred<-predict(rf.caret,newdata=validate)
rf.caret.pred<-predict(rf.caret,newdata=validate)
rf.caret.out<-confusionMatrix(rf.caret.pred,reference=validate$diabetes,positive="Yes")
rf.caret.out
rf.caret
rf.caret<- train(diabetes~., data=train, method="rf", trControl=fitcontrol,tuneLength=20)
rf.caret
rf.caret<- train(diabetes~., data=train, method="rf", trControl=fitcontrol,tuneLength=6,
preProcess=c("center","scale"))
rf.caret
rf.caret.pred<-predict(rf.caret,newdata=validate)
rf.caret.out<-confusionMatrix(rf.caret.pred,reference=validate$diabetes,positive="Yes")
rf.caret.out
set.seed(1234)
bt.caret<- train(diabetes~., data=train, method="bstTree", trControl=fitcontrol,tuneLength=6,
preProcess=c("center","scale"))
bt.caret<- train(diabetes~., data=train, method="bstTree", trControl=fitcontrol,tuneLength=6,
preProcess=c("center","scale"))
