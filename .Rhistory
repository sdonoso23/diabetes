rownames_to_column(var = "var1") %>%
gather(timespreg:age,key = var2,value = value)
ggplot()+geom_tile(data=corr,aes(x=var1, y=var2,fill=value))
finaldataset<-dataset[dataset$plaglu!=0,]
finaldataset<-finaldataset[finaldataset$bmi!=0,]
finaldataset<-finaldataset[,c(-4,-5)]
diastolic<-dataset[dataset$diastolic!=0,]
mu<-mean(diastolic$diastolic)
finaldataset<-mutate(finaldataset,diastolic=ifelse(diastolic==0,mu,diastolic))
rm(diastolic)
set.seed(1234)
trainidx<-createDataPartition(y = finaldataset$diabetes,
list = FALSE,p = 0.7)
train<-finaldataset[trainidx,]
notrain<-finaldataset[-trainidx,]
testidx<-createDataPartition(y=notrain$diabetes,list=FALSE,p=0.5)
test<-notrain[testidx,]
validate<-notrain[-testidx,]
table(train$diabetes)/nrow(train)
table(test$diabetes)/nrow(test)
table(validate$diabetes)/nrow(validate)
dtree<-rpart(diabetes~.,data=train,method="class")
summary(dtree)
printcp(dtree)
summary(dtree)
printcp(dtree)
prune(dtree,cp = 0.16)
prune(dtree,cp = 0.13)
prune(dtree,cp = 0.13514)
prune(dtree,cp = 0.1)
printcp(dtree)
a<-printcp(dtree)
plot(a$nsplit,a$xerror)
plot(a[,2],a$xerror[,5])
plot(a[,2],a[,5])
prune(dtree,cp = 0.1)
printcp(dtree)
prune(dtree,cp = 0.01)
prune(dtree,cp = 0.1)
prune(dtree,cp = 0.02)
dtree.prune<-prune(dtree,cp = 0.02)
dtree.pred<-predict(dtree,validate,type = "class")
dtree.pred
dtree.prune.pred<-predict(dtree.prune,validate,type="class")
plot(dtree.prune,margin=0.2)
text(dtree.prune,all=TRUE,use.n = TRUE,cex=0.5)
plot(dtree,margin=0.2)
text(dtree,all=TRUE,use.n = TRUE,cex=0.5)
confusionMatrix(data=dtree.prune.pred,reference = validate$diabetes,positive="Yes")
confusionMatrix(data=dtree.pred,reference = validate$diabetes,positive="Yes")
?tree
confusionMatrix(data=dtree.prune.pred,reference = validate$diabetes,positive="Yes")
multiplot(plotlist = plotlist,cols=3)
dtree2<-tree(diabetes~.,data=train,method = "class")
dtree2.pred<-predict(dtree2,validate,type="class")
confusionMatrix(data=dtree2.pred,reference=validate$diabetes)
dtree2<-tree(diabetes~.,data=train,method = "class")
dtree2.pred<-predict(dtree2,validate,type="class")
cv.dtree<-cv.tree(dtree2,FUN=prune.misclass)
cv.dtree2<-cv.tree(dtree2,FUN=prune.misclass)
dtree.prune2<-prune.misclass(dtree2,best=9)
dtree2.prune.pred<-predict(dtree.prune2,validate,type="class")
dtree2.prune<-prune.misclass(dtree2,best=9)
lista<-list()
missrate<-c()
for (i in 1:25){
a<-knn(train = train[,-7],test=validate[,-7],k = i,cl=validate$diabetes)
lista[[i]]<-a
missrate[i]<-mean(ifelse(lista[[i]]==validate$diabetes,FALSE,TRUE))
}
for (i in 1:25){
a<-knn(train = train[,-7],test=validate[,-7],k = i,cl=train$diabetes)
lista[[i]]<-a
missrate[i]<-mean(ifelse(lista[[i]]==validate$diabetes,FALSE,TRUE))
}
vector<-c(1:25)
plot(vector,missrate)
confusionMatrix(data=lista[[17]],reference=validate$diabetes,positive="Yes")
naivetrain<-train[,-7]
naivelabels<-train
naive<-train(naivetrain,naivelabels,"nb",trControl=trainControl(method="cv",number=10))
library(e1071)
naive<-train(naivetrain,naivelabels,"nb",trControl=trainControl(method="cv",number=10))
naivelabels<-train[,7]
naive<-train(naivetrain,naivelabels,"nb",trControl=trainControl(method="cv",number=10))
naive<-train(naivetrain,naivelabels,"nb",trControl=trainControl(method="cv",number=10))
naive<-train(naivetrain,naivelabels,"nb",trControl=trainControl(method="cv",number=10))
naivelabels<-train$diabetes
naive<-train(naivetrain,naivelabels,"nb",trControl=trainControl(method="cv",number=10))
naive.pred<-predict(naive,newdata = validate,type = "raw")
confusionMatrix(data=naive.pred,reference=validate$diabetes,positive="Yes")
dtree2.pred<-predict(dtree2,validate,type="prob")
dtree2.pred<-predict(dtree2,validate,type="vector")
View(dtree2.pred)
View(dtree2.pred)
dtree.prune.pred<-predict(dtree.prune,validate,type="prob")
ggplot()+geom_tile(data=corr,aes(x=var1, y=var2,fill=value))
plot(dataset)
ggplot()+geom_tile(data=corr,aes(x=var1, y=var2,fill=value))
ggplot()+geom_bar(data=finaldataset,x=diabetes)
ggplot()+geom_bar(data=finaldataset,aes(x=diabetes))
ggplot()+geom_bar(data=finaldataset,aes(x=diabetes),stat="bin")
ggplot()+geom_bar(data=finaldataset,aes(x=diabetes),stat="count")
table(finaldataset$diabetes)
ggplot()+geom_tile(data=corr,aes(x=var1, y=var2,fill=value))
cor(finaldataset)
cor(finaldataset[,-7])
write_csv2(cor(finaldataset[,-7]),"correlation.csv")
write_csv(cor(finaldataset[,-7]),"correlation.csv")
write_csv(as.data.frame(cor(finaldataset[,-7])),"correlation.csv")
options(scipen=15)
cor(finaldataset[,-7])
confusionMatrix(data=naive.pred,reference=validate$diabetes,positive="Yes")
ggplot()+geom_tile(data=corr,aes(x=var1, y=var2,fill=value))+geom_label(aes(label=value))
ggplot()+geom_tile(data=corr,aes(x=var1, y=var2,fill=value))+geom_label(aes(label=value))
ggplot()+geom_tile(data=corr,aes(x=var1, y=var2,fill=value))
confusionMatrix(data=lista[[17]],reference=validate$diabetes,positive="Yes")
naive
confusionMatrix(data=dtree.pred,reference = validate$diabetes,positive="Yes")
confusionMatrix(data=dtree.prune.pred,reference = validate$diabetes,positive="Yes")
dtree.prune<-prune(dtree,cp = 0.02)
dtree.prune.pred<-predict(dtree.prune,validate,type="prob")
confusionMatrix(data=dtree.prune.pred,reference = validate$diabetes,positive="Yes")
confusionMatrix(data=dtree2.pred,reference=validate$diabetes,positive="Yes")
dtree.prune.pred<-predict(dtree.prune,validate,type="class")
dtree.pred<-predict(dtree,validate,type = "class")
confusionMatrix(data=dtree.pred,reference = validate$diabetes,positive="Yes")
confusionMatrix(data=dtree.prune.pred,reference = validate$diabetes,positive="Yes")
dtree2.pred<-predict(dtree2,validate,type="class")
confusionMatrix(data=dtree2.pred,reference=validate$diabetes,positive="Yes")
dtree2.prune.pred<-predict(dtree.prune2,validate,type="class")
confusionMatrix(data=dtree2.prune.pred,reference=validate$diabetes,positive="Yes")
confusionMatrix(data=lista[[17]],reference=validate$diabetes,positive="Yes")
confusionMatrix(data=naive.pred,reference=validate$diabetes,positive="Yes")
plot(vector,missrate)
summary(dtree2)
cv.dtree2
dtree2.prune<-prune.misclass(dtree2,best=3)
dtree2.prune.pred<-predict(dtree.prune2,validate,type="class")
confusionMatrix(data=dtree2.prune.pred,reference=validate$diabetes,positive="Yes")
er<-confusionMatrix(data=naive.pred,reference=validate$diabetes,positive="Yes")
logit<-glm(diabetes~.,data=train,family=binomial(link=logit))
logit.pred<-predict(logit,newdata = validate,type="reponse")
logit.pred<-predict(logit,newdata = validate,type="response")
logit.pred.class<-ifelse(logit.pred>0.5,"Yes","No")
confusionMatrix(data=logit.pred.class,reference=validate$diabetes,positive="Yes")
confusionMatrix(data=naive.pred,reference=validate$diabetes,positive="Yes")
log(1)
log(0)
library(tidyverse)
library(MASS)
library(rpart)
library(class)
library(modelr)
library(caret)
library(tree)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(klaR)
library(e1071)
source("r/functions.R")
dataset<-read_csv("data/diabetes.txt",col_names=c("timespreg","plaglu",
"diastolic","triceps",
"serum","bmi","diabped",
"age","diabetes"))
plotlist<-multiplehist(dataset)
ggsave("plots/histograms.png",multiplot(plotlist = plotlist,cols=3))
ggplot(data=corr,aes(x=var1, y=var2,fill=value))+geom_tile()+
geom_text(aes(fill=value,label=value))
corr<-as.data.frame(cor(dataset[,-9])) %>%
rownames_to_column(var = "var1") %>%
gather(timespreg:age,key = var2,value = value)
ggplot(data=corr,aes(x=var1, y=var2,fill=value))+geom_tile()+
geom_text(aes(fill=value,label=value))
ggplot(data=corr,aes(x=var1, y=var2,fill=value))+geom_tile()+
geom_text(aes(fill=value,label=round(value,2))
write_csv(as.data.frame(cor(dataset[,-9])),"correlation.csv")
##remove rows with missing values and columns with too many missing values
finaldataset<-dataset[dataset$plaglu!=0,]
finaldataset<-finaldataset[finaldataset$bmi!=0,]
finaldataset<-finaldataset[,c(-4,-5)]
##count of diabetes
table(finaldataset$diabetes)
ggplot()+geom_bar(data=finaldataset,aes(x=diabetes),stat="count")
##replace missing values with mean in diastolic
diastolic<-dataset[dataset$diastolic!=0,]
mu<-mean(diastolic$diastolic)
finaldataset<-mutate(finaldataset,diastolic=ifelse(diastolic==0,mu,diastolic))
rm(diastolic)
##standardize variables
normalize<-as.data.frame(scale(finaldataset[,-7]))
normalize$diabetes<-finaldataset$diabetes
####DATASET PARTITION####
##sample partition
set.seed(1234)
trainidx<-createDataPartition(y = finaldataset$diabetes,
list = FALSE,p = 0.7)
train<-finaldataset[trainidx,]
notrain<-finaldataset[-trainidx,]
testidx<-createDataPartition(y=notrain$diabetes,list=FALSE,p=0.5)
test<-notrain[testidx,]
validate<-notrain[-testidx,]
##check means
table(train$diabetes)/nrow(train)
table(test$diabetes)/nrow(test)
table(validate$diabetes)/nrow(validate)
####MODELS####
####DECISION TREE#####
#define tree with function defaults:
#gini as splitting criteria, priors defined by sample,
#loss with value 1
#20 as minimum obs for a node to be splitted
#20/3 as minimum obs in a terminal node
#0.01 as minimum increase of fit for a split to be performed
dtree<-rpart(diabetes~.,data=train,method="class")
summary(dtree)
plot(dtree,margin=0.2)
text(dtree,all=TRUE,use.n = TRUE,cex=0.5)
dtree.pred<-predict(dtree,validate,type = "class")
confusionMatrix(data=dtree.pred,reference = validate$diabetes,positive="Yes")
##print results of 10-fold cross validation
#search for the tree with the lowest xerror and then choose
#the tree with the lowest number of splits within 1 sd
log(0)
printcp(dtree)
dtree.prune<-prune(dtree,cp = 0.02)
plot(dtree.prune,margin=0.2)
text(dtree.prune,all=TRUE,use.n = TRUE,cex=0.5)
dtree.prune.pred<-predict(dtree.prune,validate,type="class")
confusionMatrix(data=dtree.prune.pred,reference = validate$diabetes,positive="Yes")
##with tree package
dtree2<-tree(diabetes~.,data=train,method = "class")
summary(dtree2)
plot(dtree2)
text(dtree2,pretty=0)
###training misclassifcation = 20.3%
##prediction on test dataset
dtree2.pred<-predict(dtree2,validate,type="class")
confusionMatrix(data=dtree2.pred,reference=validate$diabetes,positive="Yes")
## test missclassifcation = 25.8%
##crossvalidation to find minimum error tree
cv.dtree2<-cv.tree(dtree2,FUN=prune.misclass)
cv.dtree2
###best tree with 9 nodes
##best model with 9 nodes
dtree2.prune<-prune.misclass(dtree2,best=3)
summary(dtree.prune)
plot(dtree.prune)
text(dtree.prune,pretty=0)
##prediction on test dataset
dtree2.prune.pred<-predict(dtree.prune2,validate,type="class")
confusionMatrix(data=dtree2.prune.pred,reference=validate$diabetes,positive="Yes")
#####KNN no normalized#####
lista<-list()
missrate<-c()
for (i in 1:25){
a<-knn(train = train[,-7],test=validate[,-7],k = i,cl=train$diabetes)
lista[[i]]<-a
missrate[i]<-mean(ifelse(lista[[i]]==validate$diabetes,FALSE,TRUE))
}
vector<-c(1:25)
plot(vector,missrate)
###lowest probability with k=17
confusionMatrix(data=lista[[17]],reference=validate$diabetes,positive="Yes")
#####NAIVE BAYES####
##separate variables in x and y
naivetrain<-train[,-7]
naivelabels<-train$diabetes
naive<-train(naivetrain,naivelabels,"nb",trControl=trainControl(method="cv",number=10))
naive
naive.pred<-predict(naive,newdata = validate,type = "raw")
confusionMatrix(data=naive.pred,reference=validate$diabetes,positive="Yes")
###LOGIT###
logit<-glm(diabetes~.,data=train,family=binomial(link=logit))
logit.pred<-predict(logit,newdata = validate,type="response")
logit.pred.class<-ifelse(logit.pred>0.5,"Yes","No")
confusionMatrix(data=logit.pred.class,reference=validate$diabetes,positive="Yes")
ggplot(data=corr,aes(x=var1, y=var2,fill=value))+geom_tile()+
geom_text(aes(fill=value,label=round(value,2)))
ggplot(data=corr,aes(x=var1, y=var2,fill=value))+geom_tile()+
geom_text(aes(label=round(value,2)))
ggplot(data=corr,aes(x=var1, y=rev(var2),fill=value))+geom_tile()+
geom_text(aes(label=round(value,2)))
ggplot(data=corr,aes(x=var1, y=var2,fill=value))+geom_tile()+
geom_text(aes(label=round(value,2)))
ggplot(data=corr,aes(x=var1, y=var2,fill=value))+geom_tile()+
geom_text(aes(label=round(value,2)),color="white")
corrplot<-ggplot(data=corr,aes(x=var1, y=var2,fill=value))+geom_tile()+
geom_text(aes(label=round(value,2)),color="white")
ggsave("plots/corrplot.png",corrplot)
ggsave("plots/corrplot.png",corrplot,width = 600,height = 349)
ggsave("plots/corrplot.png",corrplot,width = 20,height = 10,)
ggsave("plots/corrplot.png",corrplot,width = 4,height = 2,)
ggsave("plots/corrplot.png",corrplot,width = 8,height = 4,)
ggplot()+geom_bar(data=finaldataset,aes(x=diabetes),stat="count")
ggplot()+geom_bar(data=finaldataset,aes(x=diabetes),color="green",stat="count")
ggplot()+geom_bar(data=finaldataset,aes(x=diabetes),fill="green",stat="count")
ggplot()+geom_bar(data=finaldataset,aes(x=diabetes),stat="count")
ggsave("plots/diabetes.png",county,width = 8,height = 4)
county<-ggplot()+geom_bar(data=finaldataset,aes(x=diabetes),stat="count")
ggsave("plots/diabetes.png",county,width = 8,height = 4)
ggsave("plots/histograms.png",
multiplot(plotlist = plotlist,cols=3),width=8,height=4)
library(tidyverse)
library(MASS)
library(class)
library(modelr)
library(rpart)
library(caret)
library(rpart.plot)
library(rattle)
library(tree)
library(RColorBrewer)
library(klaR)
library(e1071)
source("r/functions.R")
dataset<-read_csv("data/diabetes.txt",col_names=c("timespreg","plaglu",
"diastolic","triceps",
"serum","bmi","diabped",
"age","diabetes"))
dataset$diabetes<-factor(dataset$diabetes,levels=c(0,1)
,labels = c("No","Yes"))
finaldataset<-dataset[dataset$plaglu!=0,]
finaldataset<-finaldataset[finaldataset$bmi!=0,]
finaldataset<-finaldataset[,c(-4,-5)]
diastolic<-dataset[dataset$diastolic!=0,]
mu<-mean(diastolic$diastolic)
finaldataset<-mutate(finaldataset,diastolic=ifelse(diastolic==0,mu,diastolic))
rm(diastolic)
normalize<-as.data.frame(scale(finaldataset[,-7]))
normalize$diabetes<-finaldataset$diabetes
set.seed(1234)
trainidx<-createDataPartition(y = finaldataset$diabetes,
list = FALSE,p = 0.7)
train<-finaldataset[trainidx,]
notrain<-finaldataset[-trainidx,]
set.seed(1234)
testidx<-createDataPartition(y=notrain$diabetes,list=FALSE,p=0.5)
test<-notrain[testidx,]
validate<-notrain[-testidx,]
normtrain<-normalize[trainidx,]
normnotrain<-normalize[-trainidx,]
normtest<-normnotrain[testidx,]
normvalidate<-normnotrain[-testidx,]
dtree<-rpart(diabetes~.,data=train,method="class")
summary(dtree)
dtree.pred<-predict(dtree,validate,type = "class")
confusionMatrix(data=dtree.pred,reference = validate$diabetes,positive="Yes")
printcp(dtree)
dtree.prune<-prune(dtree,cp = 0.02)
dtree.prune.pred<-predict(dtree.prune,validate,type="class")
confusionMatrix(data=dtree.prune.pred,reference = validate$diabetes,positive="Yes")
dtree2<-tree(diabetes~.,data=train,method = "class")
dtree2.pred<-predict(dtree2,validate,type="class")
confusionMatrix(data=dtree2.pred,reference=validate$diabetes,positive="Yes")
cv.dtree2<-cv.tree(dtree2,FUN=prune.misclass)
cv.dtree2
dtree2.prune<-prune.misclass(dtree2,best=3)
dtree2.prune.pred<-predict(dtree.prune2,validate,type="class")
dtree2.prune.pred<-predict(dtree2.prune,validate,type="class")
confusionMatrix(data=dtree2.prune.pred,reference=validate$diabetes,positive="Yes")
knn.pred<-list()
knn.missrate<-c()
for (i in 1:25){
a<-knn(train = normtrain[,-7],test=normvalidate[,-7],k = i,cl=normtrain$diabetes)
knn.pred[[i]]<-a
knn.missrate[i]<-mean(ifelse(lista[[i]]==normvalidate$diabetes,FALSE,TRUE))
}
for (i in 1:25){
a<-knn(train = normtrain[,-7],test=normvalidate[,-7],k = i,cl=normtrain$diabetes)
knn.pred[[i]]<-a
knn.missrate[i]<-mean(ifelse(knn.pred[[i]]==normvalidate$diabetes,FALSE,TRUE))
}
vector<-c(1:25)
names(knn.pred)<-paste("K=",c(1:25),sep="")
plot(vector,knn.missrate)
confusionMatrix(data=knn.pred[[7]],reference=normvalidate$diabetes,positive="Yes")
naivetrain<-train[,-7]
naivelabels<-train$diabetes
naive<-train(naivetrain,naivelabels,"nb",trControl=trainControl(method="cv",number=10))
naive.pred<-predict(naive,newdata = validate,type = "raw")
confusionMatrix(data=naive.pred,reference=validate$diabetes,positive="Yes")
logit<-glm(diabetes~.,data=train,family=binomial(link=logit))
logit.pred<-predict(logit,newdata = validate,type="response")
logit.pred.class<-ifelse(logit.pred>0.5,"Yes","No")
confusionMatrix(data=logit.pred.class,reference=validate$diabetes,positive="Yes")
logit
summary(logit)
logit<-glm(diabetes~timespreg+plaglu+bmi,data=train,family=binomial(link=logit))
summary(logit)
logit.pred<-predict(logit,newdata = validate,type="response")
logit.pred.class<-ifelse(logit.pred>0.5,"Yes","No")
confusionMatrix(data=logit.pred.class,reference=validate$diabetes,positive="Yes")
logit<-glm(diabetes~.,data=train,family=binomial(link=logit))
summary(logit)
logit.pred<-predict(logit,newdata = validate,type="response")
logit.pred.class<-ifelse(logit.pred>0.5,"Yes","No")
confusionMatrix(data=logit.pred.class,reference=validate$diabetes,positive="Yes")
confusionMatrix(data=naive.pred,reference=validate$diabetes,positive="Yes")
confusionMatrix(data=knn.pred[[7]],reference=normvalidate$diabetes,positive="Yes")
confusionMatrix(data=dtree2.prune.pred,reference=validate$diabetes,positive="Yes")
confusionMatrix(data=dtree2.prune.pred,reference=validate$diabetes,positive="Yes")
confusionMatrix(data=dtree2.pred,reference=validate$diabetes,positive="Yes")
confusionMatrix(data=dtree2.prune.pred,reference=validate$diabetes,positive="Yes")
confusionMatrix(data=dtree.prune.pred,reference = validate$diabetes,positive="Yes")
confusionMatrix(data=dtree.pred,reference = validate$diabetes,positive="Yes")
printcp(dtree)
library(tidyverse)
library(MASS)
library(rpart)
library(modelr)
library(class)
library(tree)
library(caret)
library(rattle)
library(RColorBrewer)
library(rpart.plot)
library(klaR)
library(e1071)
source("r/functions.R")
dataset<-read_csv("data/diabetes.txt",col_names=c("timespreg","plaglu",
"diastolic","triceps",
"serum","bmi","diabped",
"age","diabetes"))
finaldataset<-dataset[dataset$plaglu!=0,]
finaldataset<-finaldataset[finaldataset$bmi!=0,]
finaldataset<-finaldataset[,c(-4,-5)]
diastolic<-dataset[dataset$diastolic!=0,]
mu<-mean(diastolic$diastolic)
finaldataset<-mutate(finaldataset,diastolic=ifelse(diastolic==0,mu,diastolic))
rm(diastolic)
normalize<-as.data.frame(scale(finaldataset[,-7]))
normalize$diabetes<-finaldataset$diabetes
set.seed(1234)
trainidx<-createDataPartition(y = finaldataset$diabetes,
list = FALSE,p = 0.7)
train<-finaldataset[trainidx,]
notrain<-finaldataset[-trainidx,]
set.seed(1234)
testidx<-createDataPartition(y=notrain$diabetes,list=FALSE,p=0.5)
test<-notrain[testidx,]
validate<-notrain[-testidx,]
normtrain<-normalize[trainidx,]
normnotrain<-normalize[-trainidx,]
normtest<-normnotrain[testidx,]
normvalidate<-normnotrain[-testidx,]
dtree<-rpart(diabetes~.,data=train,method="class")
dtree.pred<-predict(dtree,validate,type = "class")
confusionMatrix(data=dtree.pred,reference = validate$diabetes,positive="Yes")
dataset<-read_csv("data/diabetes.txt",col_names=c("timespreg","plaglu",
"diastolic","triceps",
"serum","bmi","diabped",
"age","diabetes"))
dataset$diabetes<-factor(dataset$diabetes,levels=c(0,1)
,labels = c("No","Yes"))
finaldataset<-dataset[dataset$plaglu!=0,]
finaldataset<-finaldataset[finaldataset$bmi!=0,]
finaldataset<-finaldataset[,c(-4,-5)]
diastolic<-dataset[dataset$diastolic!=0,]
mu<-mean(diastolic$diastolic)
finaldataset<-mutate(finaldataset,diastolic=ifelse(diastolic==0,mu,diastolic))
rm(diastolic)
normalize<-as.data.frame(scale(finaldataset[,-7]))
normalize$diabetes<-finaldataset$diabetes
set.seed(1234)
trainidx<-createDataPartition(y = finaldataset$diabetes,
list = FALSE,p = 0.7)
train<-finaldataset[trainidx,]
notrain<-finaldataset[-trainidx,]
set.seed(1234)
testidx<-createDataPartition(y=notrain$diabetes,list=FALSE,p=0.5)
test<-notrain[testidx,]
validate<-notrain[-testidx,]
normtrain<-normalize[trainidx,]
normnotrain<-normalize[-trainidx,]
normtest<-normnotrain[testidx,]
normvalidate<-normnotrain[-testidx,]
dtree<-rpart(diabetes~.,data=train,method="class")
dtree.pred<-predict(dtree,validate,type = "class")
confusionMatrix(data=dtree.pred,reference = validate$diabetes,positive="Yes")
dtree.prune<-prune(dtree,cp = 0.02)
dtree.prune.pred<-predict(dtree.prune,validate,type="class")
confusionMatrix(data=dtree.prune.pred,reference = validate$diabetes,positive="Yes")
dtree2<-tree(diabetes~.,data=train,method = "class")
dtree2.pred<-predict(dtree2,validate,type="class")
confusionMatrix(data=dtree2.pred,reference=validate$diabetes,positive="Yes")
cv.dtree2<-cv.tree(dtree2,FUN=prune.misclass)
dtree2.prune<-prune.misclass(dtree2,best=3)
dtree2.prune.pred<-predict(dtree2.prune,validate,type="class")
confusionMatrix(data=dtree2.prune.pred,reference=validate$diabetes,positive="Yes")
knn.pred<-list()
knn.missrate<-c()
for (i in 1:25){
a<-knn(train = normtrain[,-7],test=normvalidate[,-7],k = i,cl=normtrain$diabetes)
knn.pred[[i]]<-a
knn.missrate[i]<-mean(ifelse(knn.pred[[i]]==normvalidate$diabetes,FALSE,TRUE))
}
vector<-c(1:25)
names(knn.pred)<-paste("K=",c(1:25),sep="")
plot(vector,knn.missrate)
confusionMatrix(data=knn.pred[[7]],reference=normvalidate$diabetes,positive="Yes")
naivetrain<-train[,-7]
naivelabels<-train$diabetes
naive<-train(naivetrain,naivelabels,"nb",trControl=trainControl(method="cv",number=10))
naive.pred<-predict(naive,newdata = validate,type = "raw")
confusionMatrix(data=naive.pred,reference=validate$diabetes,positive="Yes")
logit<-glm(diabetes~.,data=train,family=binomial(link=logit))
summary(logit)
logit.pred<-predict(logit,newdata = validate,type="response")
logit.pred.class<-ifelse(logit.pred>0.5,"Yes","No")
confusionMatrix(data=logit.pred.class,reference=validate$diabetes,positive="Yes")
